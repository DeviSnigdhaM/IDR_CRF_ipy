{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Image Is Worth a Thousand Words\n",
    "### Build Your First Intelligent Document Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Dataset\n",
    "The datasets used in this workshop will be introduced to the attendees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnnotationSet = \"datasets/Annotations\"\n",
    "cleanOCRSet = \"datasets/CleanOCR\"\n",
    "nerDataset = \"datasets/ner-dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to OCR\n",
    "Attendees will be apply OCR on a sample image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Annotation and BIO Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataAnnotation():\n",
    "\tallCleanOCRFiles = os.listdir(cleanOCRSet)\n",
    "\tallIXFiles = os.listdir(AnnotationSet)\n",
    "\toutfile = open(nerDataset, 'w')\n",
    "\treceiptNum = 1\n",
    "\toutfile.write('Receipt #,Word,POS,Tag' + '\\n')\n",
    "\n",
    "\tfor ixfile in allIXFiles:\n",
    "\t\tfilename = os.fsdecode(ixfile)\n",
    "\t\tfor ocrfile in allCleanOCRFiles:\n",
    "\t\t\tocrFilename = os.fsdecode(ocrfile)\n",
    "\t\t\tif filename == ocrFilename:\n",
    "\t\t\t\tixData = {}\n",
    "\t\t\t\tocrCleanLine = \"\"\n",
    "\t\t\t\twith open(AnnotationSet + '/' + filename) as f1:\n",
    "\t\t\t\t\tixData = json.load(f1)\n",
    "\t\t\t\twith open(cleanOCRSet + '/' + filename) as f2:\n",
    "\t\t\t\t\tocrCleanLine = f2.readlines()\n",
    "\t\t\t\tannotationLine = \"\"\n",
    "\t\t\t\twordNum = 0\n",
    "\t\t\t\twords = ocrCleanLine[0].replace(',', '').split(' ')\n",
    "\t\t\t\tisAmount = False\n",
    "\t\t\t\tisDate = False\n",
    "\t\t\t\tisMerchant = False\n",
    "\t\t\t\tbeginMerchant = False\n",
    "\t\t\t\tbeginDate = False\n",
    "\n",
    "\t\t\t\tmerchantParts = ixData['company'].split(' ')\n",
    "\t\t\t\tdateParts = ixData['date'].split(' ')\n",
    "\t\t\t\t\n",
    "\t\t\t\tfor word in words:\n",
    "\t\t\t\t\tannotationLine = \"\"\n",
    "\t\t\t\t\tword = word.replace(',', ' ')\n",
    "\t\t\t\t\tif wordNum == 0:\n",
    "\t\t\t\t\t\tif word == dateParts[0] and not isDate:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"DT\" + ',' + 'B-date'\n",
    "\t\t\t\t\t\t\tisDate = True\n",
    "\t\t\t\t\t\t\t# Only expect a I-date if there are multiple parts to the date\n",
    "\t\t\t\t\t\t\tif len(dateParts) > 1:\n",
    "\t\t\t\t\t\t\t\tbeginDate = True\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tbeginDate = False\n",
    "\t\t\t\t\t\telif word == ixData['total'] and not isAmount:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"AM\" + ',' + 'B-amt'\n",
    "\t\t\t\t\t\t\tisAmount = True\n",
    "\t\t\t\t\t\telif word == merchantParts[0] and not isMerchant:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"MR\" + ',' + 'B-mer'\n",
    "\t\t\t\t\t\t\tisMerchant = True\n",
    "\t\t\t\t\t\t\tbeginMerchant = True\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"NN\" + ',' + 'O'\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t#Date tagging\n",
    "\t\t\t\t\t\tif word == dateParts[0] and not isDate:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"DT\" + ',' + 'B-date'\n",
    "\t\t\t\t\t\t\tisDate = True\n",
    "\t\t\t\t\t\t\t# Only expect a I-date if there are multiple parts to the date\n",
    "\t\t\t\t\t\t\tif len(dateParts) > 1:\n",
    "\t\t\t\t\t\t\t\t# print(\"This date has many parts: \" + ixData['date'])\n",
    "\t\t\t\t\t\t\t\tbeginDate = True\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tbeginDate = False\n",
    "\t\t\t\t\t\telif word in ixData['date'] and word != dateParts[0] and word != dateParts[-1] and beginDate:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"DT\" + ',' + 'I-date'\n",
    "\t\t\t\t\t\telif word == dateParts[-1] and beginDate:\n",
    "\t\t\t\t\t\t\tbeginDate = False\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"DT\" + ',' + 'I-date'\n",
    "\n",
    "\t\t\t\t\t\t#Amount tagging\n",
    "\t\t\t\t\t\telif word == ixData['total'] and not isAmount:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"AM\" + ',' + 'B-amt'\n",
    "\t\t\t\t\t\t\tisAmount = True\n",
    "\n",
    "\t\t\t\t\t\t#Merchant tagging\n",
    "\t\t\t\t\t\telif word == merchantParts[0] and not isMerchant:\n",
    "\t\t\t\t\t\t\tbeginMerchant = True\n",
    "\t\t\t\t\t\t\tisMerchant = True\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"MR\" + ',' + 'B-mer'\n",
    "\t\t\t\t\t\telif word in ixData['company'] and word != merchantParts[0] and word != merchantParts[-1] and beginMerchant:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"MR\" + ',' + 'I-mer'\n",
    "\t\t\t\t\t\telif word == merchantParts[-1] and beginMerchant:\n",
    "\t\t\t\t\t\t\tbeginMerchant = False\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"MR\" + ',' + 'I-mer'\n",
    "\n",
    "\t\t\t\t\t\t#Other tagging\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"NN\" + ',' + 'O'\n",
    "\t\t\t\t\twordNum += 1\t\t\t\t\t\t\n",
    "\t\t\t\t\t#print(annotationLine)\n",
    "\t\t\t\t\toutfile.write(annotationLine + '\\n')\n",
    "\t\t\t\treceiptNum += 1\n",
    "\toutfile.close\n",
    "    \n",
    "dataAnnotation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "df = pd.read_csv('datasets/ner-dataset.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "#Display first 10 rows\n",
    "df.head(10)\n",
    "df.describe()\n",
    "#Displaying the unique Tags\n",
    "df['Tag'].unique()\n",
    "#Checking null values, if any.\n",
    "df.isnull().sum()\n",
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Receipt #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Receipt: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]\n",
    "\n",
    "#sentence with its pos and tag.\n",
    "sent = getter.get_text()\n",
    "# print(sent)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \"\"  \n",
    "    \n",
    "    # traverse in the string   \n",
    "    for ele in s:  \n",
    "        str1 += ele   \n",
    "    \n",
    "    # return string   \n",
    "    return str1\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.6)\n",
    "\n",
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test set.\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "\tprediction = y_pred[i]\n",
    "\ttestList = X_test[i]\n",
    "\ttestSentence = \"\"\n",
    "\tfor testTuple in testList:\n",
    "\t\ttestSentence = testSentence + testTuple['word.lower()'] + ' '\n",
    "\twords = testSentence.split(\" \")\n",
    "\tx = 0\n",
    "\tfor wordPrediction in prediction:\n",
    "\t\tif wordPrediction == 'B-date' or wordPrediction == 'B-amt' or wordPrediction == 'B-mer' or wordPrediction == 'I-mer' or wordPrediction == 'I-date':\n",
    "\t\t\tprint(words[x],wordPrediction)\n",
    "\t\tx +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted')\n",
    "print(f1_score)\n",
    "\n",
    "report = flat_classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application\n",
    "The attendees will be asked to extend the above example to add a new field for extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sentence(test_file):\n",
    "    #Reading the csv file\n",
    "    trial = pd.read_csv(test_file, encoding = \"ISO-8859-1\")\n",
    "\n",
    "    #Display first 10 rows\n",
    "    trial.head(10)\n",
    "    trial.describe()\n",
    "    #Displaying the unique Tags\n",
    "    trial['Tag'].unique()\n",
    "    #Checking null values, if any.\n",
    "    trial.isnull().sum()\n",
    "    trial = trial.fillna(method = 'ffill')\n",
    "    trial_getter = sentence(trial) # Check last token - seems to be repeating \n",
    "    trial_sentences = [\" \".join([s[0] for s in sent]) for sent in trial_getter.sentences]\n",
    "    trial_sentences[0]\n",
    "\n",
    "    #sentence with its pos and tag.\n",
    "    trial_sent = trial_getter.get_text()\n",
    "    trial_sentences = trial_getter.sentences\n",
    "    return trial_sentences\n",
    "\n",
    "test_file = \"/path/to/trial/file\"\n",
    "trial_sentences = get_test_sentence(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = [sent2features(s) for s in trial_sentences]\n",
    "ty = [sent2labels(s) for s in trial_sentences]\n",
    "\n",
    "#Predicting on the one test set.\n",
    "X_test = tX\n",
    "y_test = ty\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted')\n",
    "print(f1_score)\n",
    "\n",
    "report = flat_classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
