{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to Information\n",
    "#### Extracting Named Entities using Conditional Random Fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "The dataset used in this workshop will be introduced to the attendees. Open a file in the below folders to look at the structure of the OCR outputs and annotations for the dataset we're using for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allOCRSet = \"datasets/CleanOCR\" # A folder with all OCR files\n",
    "annotationSet = \"datasets/Annotations\" # A folder with all Annotation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to OCR\n",
    "Use Pytesseract to apply OCR on a sample receipt image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "image_path = \"datasets/SplitYB.png\" # Receipt image from a restaurant\n",
    "\n",
    "def getOCRText(image_path):\n",
    "    image_data = Image.open(image)\n",
    "    image_text = pytesseract.image_to_string(image_data)\n",
    "    return text\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Labeling\n",
    "Tokenize, Annotate and Tag a receipt for the total amount and merchant/business name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerDataset = \"datasets/ner-dataset.csv\"\n",
    "def dataAnnotation():\n",
    "\tallCleanOCRFiles = os.listdir(allOCRSet) # Load all Clean OCR Files\n",
    "\tallIXFiles = os.listdir(AnnotationSet) # Load all Clean OCR Files\n",
    "\toutfile = open(nerDataset, 'w')\n",
    "\treceiptNum = 1\n",
    "\toutfile.write('Receipt #,Word,POS,Tag' + '\\n')\n",
    "\n",
    "\tfor ixfile in allIXFiles:\n",
    "\t\tfilename = os.fsdecode(ixfile)\n",
    "\t\tfor ocrfile in allCleanOCRFiles:\n",
    "\t\t\tocrFilename = os.fsdecode(ocrfile)\n",
    "\t\t\tif filename == ocrFilename:\n",
    "\t\t\t\tixData = {}\n",
    "\t\t\t\tocrCleanLine = \"\"\n",
    "\t\t\t\twith open(AnnotationSet + '/' + filename) as f1:\n",
    "\t\t\t\t\tixData = json.load(f1)\n",
    "\t\t\t\twith open(allOCRSet + '/' + filename) as f2:\n",
    "\t\t\t\t\tocrCleanLine = f2.readlines()\n",
    "\t\t\t\tannotationLine = \"\"\n",
    "\t\t\t\twordNum = 0\n",
    "\t\t\t\twords = ocrCleanLine[0].replace(',', '').split(' ')\n",
    "\t\t\t\tisAmount = False\n",
    "\t\t\t\tisDate = False\n",
    "\t\t\t\tisMerchant = False\n",
    "\t\t\t\tbeginMerchant = False\n",
    "\t\t\t\tbeginDate = False\n",
    "\n",
    "\t\t\t\tmerchantParts = ixData['company'].split(' ')\n",
    "\t\t\t\tdateParts = ixData['date'].split(' ')\n",
    "\t\t\t\t\n",
    "\t\t\t\tfor word in words:\n",
    "\t\t\t\t\tannotationLine = \"\"\n",
    "\t\t\t\t\tword = word.replace(',', ' ')\n",
    "\t\t\t\t\tif wordNum == 0:\n",
    "\t\t\t\t\t\tif word == dateParts[0] and not isDate:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"DT\" + ',' + 'B-date'\n",
    "\t\t\t\t\t\t\tisDate = True\n",
    "\t\t\t\t\t\t\t# Only expect a I-date if there are multiple parts to the date\n",
    "\t\t\t\t\t\t\tif len(dateParts) > 1:\n",
    "\t\t\t\t\t\t\t\tbeginDate = True\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tbeginDate = False\n",
    "\t\t\t\t\t\telif word == ixData['total'] and not isAmount:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"AM\" + ',' + 'B-amt'\n",
    "\t\t\t\t\t\t\tisAmount = True\n",
    "\t\t\t\t\t\telif word == merchantParts[0] and not isMerchant:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"MR\" + ',' + 'B-mer'\n",
    "\t\t\t\t\t\t\tisMerchant = True\n",
    "\t\t\t\t\t\t\tbeginMerchant = True\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tannotationLine = 'Receipt: ' + str(receiptNum) + ',' + word + ',' + \"NN\" + ',' + 'O'\n",
    "\t\t\t\t\telse:\n",
    "                        # Date tagging\n",
    "                        \n",
    "\t\t\t\t\t\t# Amount tagging\n",
    "\t\t\t\t\t\telif word == ixData['total'] and not isAmount:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"AM\" + ',' + 'B-amt'\n",
    "\t\t\t\t\t\t\tisAmount = True\n",
    "\n",
    "\t\t\t\t\t\t# Merchant tagging\n",
    "\t\t\t\t\t\telif word == merchantParts[0] and not isMerchant:\n",
    "\t\t\t\t\t\t\tbeginMerchant = True\n",
    "\t\t\t\t\t\t\tisMerchant = True\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"MR\" + ',' + 'B-mer'\n",
    "\t\t\t\t\t\telif word in ixData['company'] and word != merchantParts[0] and word != merchantParts[-1] and beginMerchant:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"MR\" + ',' + 'I-mer'\n",
    "\t\t\t\t\t\telif word == merchantParts[-1] and beginMerchant:\n",
    "\t\t\t\t\t\t\tbeginMerchant = False\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"MR\" + ',' + 'I-mer'\n",
    "\n",
    "\t\t\t\t\t\t#Other tagging\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"NN\" + ',' + 'O'\n",
    "\t\t\t\t\twordNum += 1\t\t\t\t\t\t\n",
    "\t\t\t\t\t#print(annotationLine)\n",
    "\t\t\t\t\toutfile.write(annotationLine + '\\n')\n",
    "\t\t\t\treceiptNum += 1\n",
    "\toutfile.close\n",
    "    \n",
    "dataAnnotation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model Training\n",
    "Train a model using Conditional Random Fields algorithm with Named Entity Recognition concept to extract amount and merchant fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "df = pd.read_csv('datasets/ner-dataset.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "#Display first 10 rows\n",
    "df.head(10)\n",
    "df.describe()\n",
    "#Displaying the unique Tags\n",
    "df['Tag'].unique()\n",
    "#Checking null values, if any.\n",
    "df.isnull().sum()\n",
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Receipt #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Receipt: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]\n",
    "\n",
    "#sentence with its pos and tag.\n",
    "sent = getter.get_text()\n",
    "# print(sent)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \"\"  \n",
    "    \n",
    "    # traverse in the string   \n",
    "    for ele in s:  \n",
    "        str1 += ele   \n",
    "    \n",
    "    # return string   \n",
    "    return str1\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.6)\n",
    "\n",
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test set.\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "\tprediction = y_pred[i]\n",
    "\ttestList = X_test[i]\n",
    "\ttestSentence = \"\"\n",
    "\tfor testTuple in testList:\n",
    "\t\ttestSentence = testSentence + testTuple['word.lower()'] + ' '\n",
    "\twords = testSentence.split(\" \")\n",
    "\tx = 0\n",
    "\tfor wordPrediction in prediction:\n",
    "\t\tif wordPrediction == 'B-date' or wordPrediction == 'B-amt' or wordPrediction == 'B-mer' or wordPrediction == 'I-mer' or wordPrediction == 'I-date':\n",
    "\t\t\tprint(words[x],wordPrediction)\n",
    "\t\tx +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Report\n",
    "Print the results of how your model was trained and tested to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted')\n",
    "print(f1_score)\n",
    "\n",
    "report = flat_classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application\n",
    "Go back above to Text Labeling section and add the below code under #Date Tagging section. Continue with the steps to generate a model that now extracts 3 fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\t\t\t\t# Date tagging\n",
    "\t\t\t\t\t\tif word == dateParts[0] and not isDate:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"DT\" + ',' + 'B-date'\n",
    "\t\t\t\t\t\t\tisDate = True\n",
    "\t\t\t\t\t\t\t# Only expect a I-date if there are multiple parts to the date\n",
    "\t\t\t\t\t\t\tif len(dateParts) > 1:\n",
    "\t\t\t\t\t\t\t\t# print(\"This date has many parts: \" + ixData['date'])\n",
    "\t\t\t\t\t\t\t\tbeginDate = True\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tbeginDate = False\n",
    "\t\t\t\t\t\telif word in ixData['date'] and word != dateParts[0] and word != dateParts[-1] and beginDate:\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"DT\" + ',' + 'I-date'\n",
    "\t\t\t\t\t\telif word == dateParts[-1] and beginDate:\n",
    "\t\t\t\t\t\t\tbeginDate = False\n",
    "\t\t\t\t\t\t\tannotationLine = ',' + word + ',' + \"DT\" + ',' + 'I-date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test End to End by uploading a new image - OCR to NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_path = \"datasets/new-image.png\"\n",
    "test_file = getOCRText(new_iamge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sentence(test_file):\n",
    "    #Reading the csv file\n",
    "    trial = pd.read_csv(test_file, encoding = \"ISO-8859-1\")\n",
    "\n",
    "    #Display first 10 rows\n",
    "    trial.head(10)\n",
    "    trial.describe()\n",
    "    #Displaying the unique Tags\n",
    "    trial['Tag'].unique()\n",
    "    #Checking null values, if any.\n",
    "    trial.isnull().sum()\n",
    "    trial = trial.fillna(method = 'ffill')\n",
    "    trial_getter = sentence(trial) # Check last token - seems to be repeating \n",
    "    trial_sentences = [\" \".join([s[0] for s in sent]) for sent in trial_getter.sentences]\n",
    "    trial_sentences[0]\n",
    "\n",
    "    #sentence with its pos and tag.\n",
    "    trial_sent = trial_getter.get_text()\n",
    "    trial_sentences = trial_getter.sentences\n",
    "    return trial_sentences\n",
    "\n",
    "trial_sentences = get_test_sentence(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = [sent2features(s) for s in trial_sentences]\n",
    "ty = [sent2labels(s) for s in trial_sentences]\n",
    "\n",
    "#Predicting on the one test set.\n",
    "X_test = tX\n",
    "y_test = ty\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted')\n",
    "print(f1_score)\n",
    "\n",
    "report = flat_classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
